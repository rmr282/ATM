{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('SEM-2012-SharedTask-CD-SCO-training-simple.v2.txt', sep=\"\\t\", header=None)\n",
    "data.columns = ['annotator', 'sentence_id', 'token_id', 'token', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pipeline \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define punctuations\n",
    "punctuations = string.punctuation\n",
    "punctuations = punctuations.replace(\"'\", '')\n",
    "punctuations = punctuations.replace('`', '')\n",
    "\n",
    "# define stopwords\n",
    "all_stopwords = stopwords.words('english')\n",
    "adjusted_stopwords = [e for e in all_stopwords if e not in ('ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\",\n",
    "'don', \"don't\", 'should', 't', 'can', 'no', 'nor', 'not', 'only', 'do', 'does', 'are', 'was', 'were', 'have', 'has', 'had', 'against', 'by', 'the', 'for')]\n",
    "\n",
    "# function for removing punctiations\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lowering, removing punctuations and deleting stopwords \n",
    "data['token_lower'] = data['token'].str.lower()\n",
    "data['token_no_punct'] = data['token_lower'].apply(remove_punctuations)\n",
    "data['token_no_stop'] = data['token_no_punct'].apply(lambda x: ' '.join([word for word in x.split() if word not in (adjusted_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove examples with empty token \n",
    "data['token_no_stop'].replace('', np.nan, inplace=True)\n",
    "data.dropna(subset=['token_no_stop'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_lower</th>\n",
       "      <th>token_no_punct</th>\n",
       "      <th>token_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>O</td>\n",
       "      <td>chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "      <td>1.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "      <td>mr.</td>\n",
       "      <td>mr</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "      <td>holmes</td>\n",
       "      <td>holmes</td>\n",
       "      <td>holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65444</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>56</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65445</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>57</td>\n",
       "      <td>russet</td>\n",
       "      <td>O</td>\n",
       "      <td>russet</td>\n",
       "      <td>russet</td>\n",
       "      <td>russet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>O</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>O</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34877 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            annotator  sentence_id  token_id     token label token_lower  \\\n",
       "0      baskervilles01            0         0   Chapter     O     chapter   \n",
       "1      baskervilles01            0         1        1.     O          1.   \n",
       "2      baskervilles01            0         2       Mr.     O         mr.   \n",
       "3      baskervilles01            0         3  Sherlock     O    sherlock   \n",
       "4      baskervilles01            0         4    Holmes     O      holmes   \n",
       "...               ...          ...       ...       ...   ...         ...   \n",
       "65444  baskervilles14          270        56       the     O         the   \n",
       "65445  baskervilles14          270        57    russet     O      russet   \n",
       "65446  baskervilles14          270        58    slopes     O      slopes   \n",
       "65448  baskervilles14          270        60       the     O         the   \n",
       "65449  baskervilles14          270        61      moor     O        moor   \n",
       "\n",
       "      token_no_punct token_no_stop  \n",
       "0            chapter       chapter  \n",
       "1                  1             1  \n",
       "2                 mr            mr  \n",
       "3           sherlock      sherlock  \n",
       "4             holmes        holmes  \n",
       "...              ...           ...  \n",
       "65444            the           the  \n",
       "65445         russet        russet  \n",
       "65446         slopes        slopes  \n",
       "65448            the           the  \n",
       "65449           moor          moor  \n",
       "\n",
       "[34877 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0658e4561313c79abdb6145ee817af4de56f1cefe416636511aae6283741994"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
