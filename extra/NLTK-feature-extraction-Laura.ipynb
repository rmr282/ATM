{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.parse.stanford import StanfordDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65451 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            annotator  sentence_id  token_id     token label\n",
       "0      baskervilles01            0         0   Chapter     O\n",
       "1      baskervilles01            0         1        1.     O\n",
       "2      baskervilles01            0         2       Mr.     O\n",
       "3      baskervilles01            0         3  Sherlock     O\n",
       "4      baskervilles01            0         4    Holmes     O\n",
       "...               ...          ...       ...       ...   ...\n",
       "65446  baskervilles14          270        58    slopes     O\n",
       "65447  baskervilles14          270        59        of     O\n",
       "65448  baskervilles14          270        60       the     O\n",
       "65449  baskervilles14          270        61      moor     O\n",
       "65450  baskervilles14          270        62         .     O\n",
       "\n",
       "[65451 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = \"/Users/lauraalvarez/Documents/GitHub/ATM/A2/SEM-2012-SharedTask-CD-SCO-simple.v2/SEM-2012-SharedTask-CD-SCO-training-simple.v2.txt\"\n",
    "data = pd.read_csv(path_train, sep=\"\\t\", header=None, names=['annotator', 'sentence_id', 'token_id', 'token', 'label'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "\n",
    "### Lemma, POS tag, Dependency head, Dependency relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Function to get the wordnet POS, it fixes compatibility issues with the nltk POS\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file containing list of multi-negation expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by no means',\n",
       " 'on the contrary',\n",
       " 'not for the world',\n",
       " 'nothing at all',\n",
       " 'rather than',\n",
       " 'no more',\n",
       " 'no longer']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_neg_lfile = open(\"multiple-neg-list.txt\", \"r\")\n",
    "content = multiple_neg_lfile.read().lower()\n",
    "multiple_neg_list = content.split(\"\\n\")\n",
    "multiple_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>pos-tag</th>\n",
       "      <th>head</th>\n",
       "      <th>dep-rel</th>\n",
       "      <th>lemma</th>\n",
       "      <th>isPartOfNeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>nummod</td>\n",
       "      <td>1.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>5</td>\n",
       "      <td>compound</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>3</td>\n",
       "      <td>root</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>O</td>\n",
       "      <td>NNS</td>\n",
       "      <td>55</td>\n",
       "      <td>nmod</td>\n",
       "      <td>slope</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "      <td>62</td>\n",
       "      <td>case</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>DT</td>\n",
       "      <td>62</td>\n",
       "      <td>det</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>59</td>\n",
       "      <td>nmod</td>\n",
       "      <td>moor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>30</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65451 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            annotator  sentence_id  token_id     token label pos-tag  head  \\\n",
       "0      baskervilles01            0         0   Chapter     O      NN     0   \n",
       "1      baskervilles01            0         1        1.     O      CD     1   \n",
       "2      baskervilles01            0         2       Mr.     O     NNP     1   \n",
       "3      baskervilles01            0         3  Sherlock     O     NNP     5   \n",
       "4      baskervilles01            0         4    Holmes     O     NNP     3   \n",
       "...               ...          ...       ...       ...   ...     ...   ...   \n",
       "65446  baskervilles14          270        58    slopes     O     NNS    55   \n",
       "65447  baskervilles14          270        59        of     O      IN    62   \n",
       "65448  baskervilles14          270        60       the     O      DT    62   \n",
       "65449  baskervilles14          270        61      moor     O      NN    59   \n",
       "65450  baskervilles14          270        62         .     O       .    30   \n",
       "\n",
       "        dep-rel     lemma  isPartOfNeg  \n",
       "0          ROOT   Chapter            0  \n",
       "1        nummod        1.            0  \n",
       "2         punct       Mr.            0  \n",
       "3      compound  Sherlock            0  \n",
       "4          root    Holmes            0  \n",
       "...         ...       ...          ...  \n",
       "65446      nmod     slope            0  \n",
       "65447      case        of            0  \n",
       "65448       det       the            0  \n",
       "65449      nmod      moor            0  \n",
       "65450     punct         .            0  \n",
       "\n",
       "[65451 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "import os \n",
    "\n",
    "# How to set up depencency parser: https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n",
    "# Command line instruction to start server\n",
    "    #java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n",
    "    # -preload tokenize,ssplit,pos,lemma,ner,parse,depparse \\\n",
    "    # -status_port 9000 -port 9000 -timeout 15000 & \n",
    "\n",
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "column_values = data[['annotator']].values.ravel()\n",
    "annotator_ids = pd.unique(column_values)\n",
    "\n",
    "pos_tags = []\n",
    "heads = []\n",
    "dep_rels = []\n",
    "lemmas = []\n",
    "\n",
    "for annotator in annotator_ids:\n",
    "    annotator_data = data[data['annotator'] == annotator]\n",
    "    column_values = annotator_data[['sentence_id']].values.ravel()\n",
    "    sentence_ids = pd.unique(column_values)\n",
    "\n",
    "    for sent_id in sentence_ids:\n",
    "        sentence = annotator_data.loc[annotator_data['sentence_id'] == sent_id, 'token']\n",
    "        parse, = dep_parser.parse(sentence)\n",
    "        conll = parse.to_conll(4) # get the conll format\n",
    "        df = pd.DataFrame([x.split('\\t') for x in conll.split('\\n')[:-1]], columns=['word', 'pos', 'head', 'deprel'])\n",
    "        df['head'] = df['head'].astype(int)\n",
    "        head = list(df['head'].values)\n",
    "        dep_rel = list(df['deprel'].values)\n",
    "\n",
    "        for p, h, d in zip(nltk.pos_tag(sentence), head, dep_rel):\n",
    "            pos_tags.append(p[1])\n",
    "            heads.append(h)\n",
    "            dep_rels.append(d)\n",
    "            if get_wordnet_pos(p[1]): lemma = lemmatizer.lemmatize(p[0], pos=get_wordnet_pos(p[1]))\n",
    "            else: lemma = lemmatizer.lemmatize(p[0])\n",
    "            lemmas.append(lemma)\n",
    "                \n",
    "                        \n",
    "data['pos-tag'] = pos_tags\n",
    "data['head'] = heads\n",
    "data['dep-rel'] = dep_rels\n",
    "data['lemma'] = lemmas\n",
    "data['isPartOfNeg'] = 0\n",
    "data\n",
    "\n",
    "# Error example\n",
    "# data.loc[ data['sentence_id'] == 12]\n",
    "# data.loc[(data['annotator'] == 'baskervilles01') & (data['sentence_id'] == 12)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsPartOfNegation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.token = data.token.str.lower()\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    results=[]\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            results.append((ind,ind+sll-1))\n",
    "\n",
    "    return results\n",
    "\n",
    "tokens = list(data.token.values)\n",
    "for exp in multiple_neg_list:\n",
    "    exp = exp.split(' ')\n",
    "    index = find_sub_list(exp, tokens)\n",
    "    for i in index:\n",
    "        data.loc[data.index[i[0]], 'isPartOfNeg'] = 1\n",
    "        data.loc[data.index[i[1]], 'isPartOfNeg'] = 1\n",
    "        if i[1] - i[0] >1:\n",
    "            data.loc[data.index[i[1]-1], 'isPartOfNeg'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('temp_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dd83c0049ca90416432c7bf31543fa4a43c6d1cbcb766d79372bfcb46406b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
